rm = rowMeans(U)
U1 = apply(U, 2, '-', rm)
rm
U1
rowMeans(U1)
U = matrix(c(1, 2, 3, 4, 5,
2, 3, 2, 5, 3,
5, 5, 5, 3, 2),
nrow = 3, byrow = TRUE)
rm = rowMeans(U)
U1 = apply(U, 2, '-', rm)
cm1 = colMeans(U1)
U2 = apply(U, 1, '-', cm1)
cm1
U2
colMeans(U1)
U2 = apply(U1, 1, '-', cm1)
colMeans(U1)
U2
U2 = t(apply(U1, 1, '-', cm1))
U2
U1
colMeans(U2)
rowMeans(U2)
U2
U2[2,1] == -1/3
(U2[2,1] - -1/3)^2
c(1,2) %*% c(1, 3)
source('~/.active-rstudio-document', echo=TRUE)
cosim(c(1,0), c(0,1))
cosim(c(1,1),c(1,0))
cosim(c(1,1),c(1,1))
cosimalpha(c(1,1),c(1,1), 0)
x=c(1,1)
length(x)
rep(1, length(x-1))
cosimalpha = function (x, y, alpha) {
(x * c(rep (1, length(x)-1), alpha)) %*% y / sqrt((x %*% x) * (y %*% y))
}
cosimalpha(c(1,1),c(1,1), 0)
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
(x * scaling %*% y / sqrt(((scaling * x) %*% x) * ((scaling * y) %*% y))
}
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
((x * scaling) %*% y) / sqrt(((scaling * x) %*% x) * ((scaling * y) %*% y))
}
cosimalpha(c(1,1),c(1,1), 0)
cosimalpha(c(1,1),c(1,1), 1)
cosimalpha(c(1,1),c(1,1), 2)
cosimalpha(c(1,1),c(1,2), 0)
cosimalpha(c(1,1),c(1,2), 1)
3/1.4/sqrt(5)
3/1.4/sqrt(4)
3/1.4/sqrt(6)
3/sqrt(12)
3/sqrt(10)
cosimalpha(c(1,1),c(1,2), 2)
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(c(1,1),c(1,2), 2)
cosimalpha(c(1,1),c(1,2), 0)
cosimalpha(U[3,], U[2,], 0.5) < cosimalpha(U[3,], U[1,], 0.5)
cosimalpha(U[3,], U[2,], 0.5) < cosimalpha(U[2,], U[1,], 0.5)
cosimalpha(U[2,], U[3,], 0) < cosimalpha(U[3,], U[1,], 0)
cosimalpha(U[2,], U[1,], 0.5) < cosimalpha(U[3,], U[1,], 0.5)
cosimalpha(U[3,], U[2,], 1) < cosimalpha(U[2,], U[1,], 1)
cosimalpha(U[2,], U[1,], 0.5)
cosimalpha(U[2,], U[1,], 0)
U[2,]
U
cosimalpha(p[3,], p[2,], 0.5) < cosimalpha(p[2,], p[1,], 0.5)
cosimalpha(p[2,], p[3,], 0) < cosimalpha(p[3,], p[1,], 0)
cosimalpha(p[2,], p[1,], 0.5) < cosimalpha(p[3,], p[1,], 0.5)
cosimalpha(p[3,], p[2,], 1) < cosimalpha(p[2,], p[1,], 1)
cosimalpha(p[2,], p[1,], 1)
cosimalpha(p[2,], p[1,], 0)
scaling=c(1,1,1,1,0)
p
scaling=c(1,1,1,1,1,0)
scaling^2
(scaling*p[1,])%*%p[1,]
(scaling*p[2,])%*%p[2,]
(scaling*p[2,])%*%p[1,]
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(p[2,], p[1,], 0)
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
scaling
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(p[2,], p[1,], 0)
cosimalpha = function (x, y, alpha) {
scaling = c(1:(length(x)-1), alpha)
print(scaling)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(p[2,], p[1,], 0)
cosimalpha = function (x, y, alpha) {
scaling = c(rep(1,(length(x)-1)), alpha)
print(scaling)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(p[2,], p[1,], 0)
cosimalpha = function (x, y, alpha) {
scaling = c(rep(1,(length(x)-1)), alpha)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosimalpha(p[3,], p[2,], 0.5) < cosimalpha(p[2,], p[1,], 0.5)
cosimalpha(p[2,], p[3,], 0) < cosimalpha(p[3,], p[1,], 0)
cosimalpha(p[2,], p[1,], 0.5) < cosimalpha(p[3,], p[1,], 0.5)
cosimalpha(p[3,], p[2,], 1) < cosimalpha(p[2,], p[1,], 1)
cosimalpha = function (x, y, alpha) {
scaling = c(rep(1,(length(x)-1)), alpha)
((x * scaling^2) %*% y) / sqrt(((scaling^2 * x) %*% x) * ((scaling^2 * y) %*% y))
}
cosine_distance = function (x, y, alpha) {
1 - cosimalpha(x, y, alpha)
}
cosine_distance(p[3,], p[2,], 0.5) < cosine_distance(p[2,], p[1,], 0.5)
cosine_distance(p[2,], p[3,], 0) < cosine_distance(p[3,], p[1,], 0)
cosine_distance(p[2,], p[1,], 0.5) < cosine_distance(p[3,], p[1,], 0.5)
cosine_distance(p[3,], p[2,], 1) < cosine_distance(p[2,], p[1,], 1)
candidates = matrix(c(.890, -.346, -.297,
1.125, .500, -.625,
.485, -.485, .728,
-.937, .312, .156),
byrow = FALSE,
ncol = 4)
candidates
source('~/.active-rstudio-document', echo=TRUE)
i=4
candidates[,4]
candidates[,4] %*% candidates[,4]
candidates[,4] %*% first
m = matrix(c(1,1,
2,2,
3,4),
nrow = 3, byrow = TRUE)
m
m = matrix(c(1,1,
2,2,
3,4),
nrow = 2, byrow = TRUE)
m
m = matrix(c(1,1,
2,2,
3,4),
nrow = 2, byrow = FALSE)
m
svd(m)
?svd
m = matrix(c(1,1,
2,2,
3,4),
nrow = 3, byrow = TRUE)
m
svd(m)
m = matrix(c(1,1,
2,2,
3,4),
nrow = 3, byrow = TRUE)
m
r = svd(m)
r$u %*% diag(r$d)
new_matrix = m %*% t(m)
new_matrix
library("acepack", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.1")
install.packages(c("highr", "httpuv", "R6", "RcppArmadillo", "rgl", "RSQLite", "sqldf"))
pinv
ginv
library(MASS)
m=matrix(c(1,0,0, 0, 2,0, 0,0,0), nrow=3)
m
ginv(m)
system.time( {df=read.csv("/tmp/foo")})
require(data.table)
system.time( {df=read.table("/tmp/foo")})
system.time( {df=fread("/tmp/foo")})
View(df)
whos
who
object.size(df)
require(devtools)
install.packages("devtools")
require(devtools)
install_github('xgboost','tqchen',subdir='R-package')
require(xgboost)
install.packages(c("extraTrees", "sqldf"))
l=list
l=list()
l["a"]=1
l["b"]=2
l
l[["a"]]
l["a"]
g=list(x=l)
g[[x]]
g[["x"]]
g[["x"]][["a"]]
install.packages("RSofia")
df=data.frame(1=c(1,2))
df=data.frame("1"=c(1,2))
df["1",]
df[,"1"]
df
df[,"X1"]
df=data.frame(_1=c(1,2,3))
df=data.frame("_1"=c(1,2,3))
df=data.frame("_1"=c(1,2,3), X1=c(1,2,3))
df
foo=open("/tmp/foo.txt")
foo=file("/tmp/foo.txt")
writeLines("aa", foo)
writeLines("bb", foo)
close(foo)
foo=file("/tmp/foo.txt")
writeLines("bb", foo, append=TRUE)
write("bb", foo, append=TRUE)
write("aa", foo, append=TRUE)
write("00", foo, append=TRUE)
close(foo)
sink("/tmp/foo.txt")
cat("hello")
cat("boy")
cat("and girls")
sink()
sink("/tmp/foo.txt")
cat("hello\n")
cat("boy\n")
cat("and girls\n")
sink()
1+1
install.packages("bartMachine")
install.packages(c("amap", "Amelia", "BH", "biclust", "BradleyTerry2", "cairoDevice", "car", "caret", "checkpoint", "cluster", "clusterSim", "colorspace", "CORElearn", "corrgram", "devtools", "digest", "diptest", "doBy", "dplyr", "effects", "extraTrees", "fields", "flexmix", "Formula", "futile.logger", "gbm", "ggplot2", "gplots", "gWidgetsRGtk2", "Hmisc", "httr", "ipred", "jsonlite", "kernlab", "KernSmooth", "knitr", "lambda.r", "lava", "lazyeval", "LiblineaR", "magrittr", "manipulate", "mboost", "multcomp", "mvtnorm", "NbClust", "party", "prabclus", "prodlim", "proxy", "quantmod", "quantreg", "rattle", "RColorBrewer", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "reshape2", "rgl", "rmarkdown", "R.methodsS3", "RMySQL", "robustbase", "ROCR", "R.oo", "rpart", "rpart.plot", "rstudioapi", "RUnit", "R.utils", "RWeka", "RWekajars", "seriation", "SparseM", "stabs", "swirl", "TH.data", "tidyr", "TSP", "UsingR", "verification", "zoo"))
options(java.parameters = "-Xmx5000m")
library("bartMachine")
set_bart_machine_num_cores(4)
data(automobile)
automobile = na.omit(automobile)
y<-automobile$log_price
X<-automobile
X$log_price=NULL
X
str(X)
str(y)
View(X)
bt = bartMachine(X,y)
bt
plot(bt)
k_fold_cv(X,y,k_folds = 10)
rmse_by_num_trees(bt,num_replicates = 20)
bart_machine_cv <- bartMachineCV(X, y)
bart_machine_cv
investigate_var_importance(bart_machine_cv, num_replicates_for_avg = 20)
install.packages("TraMineR")
mvad.alphabet <- c("employment", "FE", "HE", "joblessness", "school",
"training")
mvad.labels <- c("employment", "further education", "higher education",
"joblessness", "school", "training")
mvad.scodes <- c("EM", "FE", "HE", "JL", "SC", "TR")
mvad.seq <- seqdef(mvad, 17:86, alphabet = mvad.alphabet, states = mvad.scodes,
labels = mvad.labels, xtstep = 6)
library(TraMineR)
data(mvad)
seqstatl(mvad[, 17:86])
mvad.alphabet <- c("employment", "FE", "HE", "joblessness", "school",
"training")
mvad.labels <- c("employment", "further education", "higher education",
"joblessness", "school", "training")
mvad.scodes <- c("EM", "FE", "HE", "JL", "SC", "TR")
mvad.seq <- seqdef(mvad, 17:86, alphabet = mvad.alphabet, states = mvad.scodes,
labels = mvad.labels, xtstep = 6)
ar(mfrow = c(2, 2))
par(mfrow = c(2, 2))
seqiplot(mvad.seq, withlegend = FALSE, border = NA)
seqiplot(mvad.seq, withlegend = FALSE)
seqiplot(mvad.seq)
seqIplot(mvad.seq, sortv = "from.start", withlegend = FALSE)
install.packages(c("pec", "rSFA", "party"))
install.packages("manipulate")
install.packages("randomForestSRC")
library(randomForestSRC)
data(veteran)
ntree<-1000
v.out<-rsf
rsf
v.out <-rsfrc
rfsrc
v.out <-rfsrc(Survrsf(time,status)~karno, data=veteran, ntree=ntree, forest=T)
View(veteran)
v.out <-rfsrc(Surv(time,status)~karno, data=veteran, ntree=ntree, forest=T)
v.out
summary(v.out)
v.out <-rfsrc(Surv(time,status)~karno+age+prior+celltype, data=veteran, ntree=ntree, forest=T)
summary(v.out)
v.out
require(randomForestSRC)
data("pbc")
pbc.f = as.formula("Surv(days,status)~.")
pbc.out = rfsrc(pbc.f, pbc, ntree = 1000,
splitrule = "logrankapprox", forest = T)
plot(pbc.out)
require(randomForestSRC)
data("pbc")
pbc.f = as.formula("Surv(days,status)~.")
pbc.out = rfsrc(pbc.f, pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
plot(pbc.out)
str(pbc.out)
pbc.out$importance
str(pbc.out$importance)
pbc.out$importance$age
(pbc.out$importance)$age
(pbc.out$importance)["age"]
pbc.out
pbc2.out = rfsrc(Surv(days,status)~.-ascites-treatment-spiders-edema-sex,
pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
pbc2.out
plot(pbc2.out)
plot.variable(pbc.out,3,partial=T,n.pred=6)
plot.variable.rfsrc(pbc.out,3,partial=T,n.pred=6)
str(pbc.out)
imp = pbc.out$importance
pnames = pbc.out$xvar.names
pnames.order = pnames[rev(order(imp))]
pnames
ntree=1000
imp = pbc.out$importance
pnames = pbc.out$xvar.names
pnames.order = pnames[rev(order(imp))]
n.pred = length(pnames.order)
pbc.err = rep(0, n.pred)
for (k in 1:n.pred){
rsf.f = "Surv(days,status)~"
rsf.f = as.formula(paste(rsf.f,
paste(pnames.order[1:k], collapse="+")))
pbc.err[k] = rfsrc(rsf.f, pbc, ntree = ntree,
splitrule = "logrankscore")$err.rate[ntree]
}
pbc.imp.out = aas.data.frame(
cbind(round(rev(sort(imp)),4),
round(pbc.err,4),
round(-diff(c(0.5,pbc.err)),4));
row.names = pnames.order)
colnames(pbc.imp.out) = c("Imp", "Err", "Drop Err")
print(pbc.imp.out)
pbc.imp.out = aas.data.frame(
cbind(round(rev(sort(imp)),4),
round(pbc.err,4),
round(-diff(c(0.5,pbc.err)),4)),
row.names = pnames.order)
colnames(pbc.imp.out) = c("Imp", "Err", "Drop Err")
print(pbc.imp.out)
pbc.imp.out = as.data.frame(
cbind(round(rev(sort(imp)),4),
round(pbc.err,4),
round(-diff(c(0.5,pbc.err)),4)),
row.names = pnames.order)
colnames(pbc.imp.out) = c("Imp", "Err", "Drop Err")
print(pbc.imp.out)
equire(randomForestSRC)
data("pbc")
pbc.f = as.formula("Surv(days,status)~.")
pbc.out = rfsrc(pbc.f, pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
plot(pbc.out)
pbc2.out = rfsrc(Surv(days,status)~.-ascites-treatment-spiders-edema-sex,
pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
require(randomForestSRC)
data("pbc")
pbc.f = as.formula("Surv(days,status)~.")
pbc.out = rfsrc(pbc.f, pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
plot(pbc.out)
pbc2.out = rfsrc(Surv(days,status)~.-ascites-treatment-spiders-edema-sex,
pbc, ntree = 1000,
splitrule = "logrankscore", forest = T)
ntree=1000
imp = pbc.out$importance
pnames = pbc.out$xvar.names
pnames.order = pnames[rev(order(imp))]
n.pred = length(pnames.order)
pbc.err = rep(0, n.pred)
for (k in 1:n.pred){
rsf.f = "Surv(days,status)~"
rsf.f = as.formula(paste(rsf.f,
paste(pnames.order[1:k], collapse="+")))
pbc.err[k] = rfsrc(rsf.f, pbc, ntree = ntree,
splitrule = "logrankscore")$err.rate[ntree]
}
pbc.imp.out = as.data.frame(
cbind(round(rev(sort(imp)),4),
round(pbc.err,4),
round(-diff(c(0.5,pbc.err)),4)),
row.names = pnames.order)
colnames(pbc.imp.out) = c("Imp", "Err", "Drop Err")
print(pbc.imp.out)
ntree=3000
imp = pbc.out$importance
pnames = pbc.out$xvar.names
pnames.order = pnames[rev(order(imp))]
n.pred = length(pnames.order)
pbc.err = rep(0, n.pred)
for (k in 1:n.pred){
rsf.f = "Surv(days,status)~"
rsf.f = as.formula(paste(rsf.f,
paste(pnames.order[1:k], collapse="+")))
pbc.err[k] = rfsrc(rsf.f, pbc, ntree = ntree,
splitrule = "logrankscore")$err.rate[ntree]
}
pbc3.imp.out = as.data.frame(
cbind(round(rev(sort(imp)),4),
round(pbc.err,4),
round(-diff(c(0.5,pbc.err)),4)),
row.names = pnames.order)
colnames(pbc3.imp.out) = c("Imp", "Err", "Drop Err")
print(pbc3.imp.out)
x=rfsrc(Surv(days,status)~bili+copper+albumin+prothrombin+sgot+age, splitrule="logrank",)
x=rfsrc(Surv(days,status)~bili+copper+albumin+prothrombin+sgot+age, veteran, splitrule="logrank",
ntree=3000)
x=rfsrc(Surv(days,status)~bili+copper+albumin+prothrombin+sgot+age, pbc, splitrule="logrank",
ntree=3000)
x
plot(x)
x$err.rate
plot(x$err.rate[1000:3000]
)
setwd("/home2/yannick2/github/Spikes/bayesian_computation_with_r")
studentdata = read.table("studentdata.txt", sep="\t", header=TRUE)
View(studentdata)
install.packages("LearnBayes")
studentdata[1,]
attach(studentdata)
table(Drink)
barplot(table(Drink), xlab="Drink", ylab="Count")
hours.of.sleep = Wakeup - ToSleep
hours.of.sleep = WakeUp - ToSleep
summary(hours.of.sleep)
barplot(hours.of.sleep)
plot(hours.of.sleep)
hist(hours.of.sleep, main="")
boxplot(hours.of.sleep~Gender, ylab="Hours of sleep")
female.haircut = Haircut[Gender == "female"]
male.haircut = Haircut[Gender == "make"]
boxplot(Haircut~Gender)
plot(jitter(ToSleep), jitter(hours.of.sleep))
fit = lm(hours.of.sleep~ToSleep)
fit
summary(fit)
fit2 = lm(hours.of.sleep~.)
fit2 = lm(hours.of.sleep~., data = studentdata)
summary(fit2)
fit2 = lm(hours.of.sleep~.-WakeUp, data = studentdata)
summary(fit2)
fit2 = lm(hours.of.sleep~.-WakeUp-Student, data = studentdata)
summary(fit2)
fit3 = lm(hours.of.sleep~Gender+ToSleep+Job, data=studentdata)
summary(fit3)
abline(fit)
abline(fit3)
plot(fit3)
hist(Dvds, main="DVD")
hist(Dvds, main="DVD", logx=T)
hist(Dvds, main="DVD", xlobg=T)
hist(Dvds, main="DVD", xlog=T)
hist(Dvds, main="DVD", xlog=T)
hist(Dvds, main="DVD", ylog=T)
hist(log(1+Dvds), main="DVD")
hist(Dvds, main="DVD")
ggplot(Dvds, aes(x=V3)) + geom_histogram() + scale_x_log10()
require(ggplot2)
ggplot(Dvds, aes(x=V3)) + geom_histogram() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram() + scale_y_log10()
ggplot(data=studentdata, aes(x=Dvds+1)) + geom_histogram() + scale_y_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram() + scale_y_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram() + scale_y_log10() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram(binwidth=20) + scale_y_log10() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram(binwidth=5) + scale_y_log10() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram(binwidth=50) + scale_y_log10() + scale_x_log10()
ggplot(data=studentdata, aes(x=Dvds)) + geom_histogram() + scale_y_log10() + scale_x_log10()
table(Dvds)
str(Dvds)
p = seq(0.05, 0.95, by = 0.1)
prior = c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)
prior = prior / sum(prior)
qplot(prior, type="h")
qplot(prior, type="h", binwidth=100)
qplot(prior, type="h", binwidth=0.1)
qplot(prior, type="h", binwidth=0.01)
plot(p, prior, type="h")
require(LearnBayes)
data=c(11,16)
post = pdisc(p, prior, data)
plot(p, post, type="h")
quantile2 = list(p=0.9, x=0.5)
quantile1 = list(p=0.5, x=0.3)
beta.select(quantile1, quantile2)
data("footballscores")
attach(footballscores)
d = favorite - underdog - spread
n = length(d)
v = sum(d^2)
