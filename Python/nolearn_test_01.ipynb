{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannick/bin/anaconda3/envs/deep/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PY2 = sys.version_info[0] == 2\n",
    "\n",
    "if PY2:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "    def pickle_load(f, encoding):\n",
    "        return pickle.load(f)\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    def pickle_load(f, encoding):\n",
    "        return pickle.load(f, encoding=encoding)\n",
    "\n",
    "DATA_URL = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
    "DATA_FILENAME = 'mnist.pkl.gz'\n",
    "\n",
    "\n",
    "def _load_data(url=DATA_URL, filename=DATA_FILENAME):\n",
    "    \"\"\"Load data from `url` and store the result in `filename`.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"Downloading MNIST dataset\")\n",
    "        urlretrieve(url, filename)\n",
    "\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        return pickle_load(f, encoding='latin-1')\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Get data with labels, split into training, validation and test set.\"\"\"\n",
    "    data = _load_data()\n",
    "    X_train, y_train = data[0]\n",
    "    X_valid, y_valid = data[1]\n",
    "    X_test, y_test = data[2]\n",
    "    y_train = numpy.asarray(y_train, dtype=numpy.int32)\n",
    "    y_valid = numpy.asarray(y_valid, dtype=numpy.int32)\n",
    "    y_test = numpy.asarray(y_test, dtype=numpy.int32)\n",
    "\n",
    "    return dict(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_dim=X_train.shape[1],\n",
    "        output_dim=10,\n",
    "    )\n",
    "\n",
    "\n",
    "def nn_example(data, max_epochs=60):\n",
    "    net1 = NeuralNet(\n",
    "        layers=[('input', layers.InputLayer),\n",
    "                ('hidden1', layers.DenseLayer),\n",
    "                ('hidden2', layers.DenseLayer),\n",
    "                ('output', layers.DenseLayer),\n",
    "                ],\n",
    "        # layer parameters:\n",
    "        input_shape=(None, 28*28),\n",
    "        hidden1_num_units=800,  # number of units in 'hidden' layer\n",
    "        hidden2_num_units=800,\n",
    "        output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        output_num_units=10,  # 10 target values for the digits 0, 1, 2, ..., 9\n",
    "\n",
    "        # optimization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.01,\n",
    "        update_momentum=0.9,\n",
    "\n",
    "        max_epochs=max_epochs,\n",
    "        verbose=2,\n",
    "        )\n",
    "\n",
    "    # Train the network\n",
    "    net1.fit(data['X_train'], data['y_train'])\n",
    "\n",
    "    # Try the network on new data\n",
    "    print(\"Feature vector (100-110): %s\" % data['X_test'][0][100:110])\n",
    "    print(\"Label: %s\" % str(data['y_test'][0]))\n",
    "    print(\"Predicted: %s\" % str(net1.predict([data['X_test'][0]])))\n",
    "\n",
    "\n",
    "def main(max_epochs=60):\n",
    "    data = load_data()\n",
    "    print(\"Got %i testing datasets.\" % len(data['X_train']))\n",
    "    nn_example(data, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore\n",
      "Got 50000 testing datasets.\n",
      "# Neural Network with 1276810 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input       784\n",
      "  1  hidden1     800\n",
      "  2  hidden2     800\n",
      "  3  output       10\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  -----\n",
      "      1       \u001b[36m0.50054\u001b[0m       \u001b[32m0.26013\u001b[0m      1.92420      0.92641  4.99s\n",
      "      2       \u001b[36m0.23542\u001b[0m       \u001b[32m0.19790\u001b[0m      1.18959      0.94273  4.88s\n",
      "      3       \u001b[36m0.17733\u001b[0m       \u001b[32m0.16315\u001b[0m      1.08687      0.95252  4.99s\n",
      "      4       \u001b[36m0.14077\u001b[0m       \u001b[32m0.14147\u001b[0m      0.99501      0.95806  5.00s\n",
      "      5       \u001b[36m0.11540\u001b[0m       \u001b[32m0.12699\u001b[0m      0.90871      0.96310  4.89s\n",
      "      6       \u001b[36m0.09637\u001b[0m       \u001b[32m0.11691\u001b[0m      0.82427      0.96617  4.81s\n",
      "      7       \u001b[36m0.08150\u001b[0m       \u001b[32m0.10939\u001b[0m      0.74504      0.96706  4.82s\n",
      "      8       \u001b[36m0.06944\u001b[0m       \u001b[32m0.10387\u001b[0m      0.66854      0.96844  4.82s\n",
      "      9       \u001b[36m0.05962\u001b[0m       \u001b[32m0.09950\u001b[0m      0.59915      0.96933  4.83s\n",
      "     10       \u001b[36m0.05145\u001b[0m       \u001b[32m0.09632\u001b[0m      0.53413      0.96983  4.85s\n",
      "     11       \u001b[36m0.04454\u001b[0m       \u001b[32m0.09374\u001b[0m      0.47512      0.97062  4.81s\n",
      "     12       \u001b[36m0.03867\u001b[0m       \u001b[32m0.09177\u001b[0m      0.42137      0.97151  7.05s\n",
      "     13       \u001b[36m0.03367\u001b[0m       \u001b[32m0.09012\u001b[0m      0.37360      0.97240  7.73s\n",
      "     14       \u001b[36m0.02934\u001b[0m       \u001b[32m0.08911\u001b[0m      0.32926      0.97329  7.73s\n",
      "     15       \u001b[36m0.02565\u001b[0m       \u001b[32m0.08861\u001b[0m      0.28944      0.97388  7.72s\n",
      "     16       \u001b[36m0.02247\u001b[0m       0.08874      0.25323      0.97408  7.75s\n",
      "     17       \u001b[36m0.01976\u001b[0m       0.08889      0.22228      0.97458  7.78s\n",
      "     18       \u001b[36m0.01745\u001b[0m       0.08914      0.19577      0.97487  7.77s\n",
      "     19       \u001b[36m0.01547\u001b[0m       0.08940      0.17299      0.97527  7.78s\n",
      "     20       \u001b[36m0.01374\u001b[0m       0.08909      0.15427      0.97556  7.78s\n",
      "     21       \u001b[36m0.01224\u001b[0m       0.08890      0.13773      0.97576  7.77s\n",
      "     22       \u001b[36m0.01092\u001b[0m       \u001b[32m0.08827\u001b[0m      0.12370      0.97655  7.79s\n",
      "     23       \u001b[36m0.00976\u001b[0m       \u001b[32m0.08793\u001b[0m      0.11103      0.97675  7.83s\n",
      "     24       \u001b[36m0.00876\u001b[0m       \u001b[32m0.08748\u001b[0m      0.10014      0.97665  7.85s\n",
      "     25       \u001b[36m0.00789\u001b[0m       \u001b[32m0.08718\u001b[0m      0.09049      0.97685  7.85s\n",
      "     26       \u001b[36m0.00713\u001b[0m       \u001b[32m0.08705\u001b[0m      0.08193      0.97715  7.83s\n",
      "     27       \u001b[36m0.00648\u001b[0m       \u001b[32m0.08698\u001b[0m      0.07444      0.97715  7.84s\n",
      "     28       \u001b[36m0.00589\u001b[0m       \u001b[32m0.08698\u001b[0m      0.06777      0.97695  7.84s\n",
      "     29       \u001b[36m0.00539\u001b[0m       0.08698      0.06196      0.97695  7.85s\n",
      "     30       \u001b[36m0.00495\u001b[0m       0.08709      0.05687      0.97725  7.86s\n",
      "     31       \u001b[36m0.00457\u001b[0m       0.08726      0.05233      0.97725  7.86s\n",
      "     32       \u001b[36m0.00423\u001b[0m       0.08747      0.04832      0.97715  7.87s\n",
      "     33       \u001b[36m0.00393\u001b[0m       0.08764      0.04482      0.97744  7.86s\n",
      "     34       \u001b[36m0.00366\u001b[0m       0.08789      0.04167      0.97784  7.87s\n",
      "     35       \u001b[36m0.00342\u001b[0m       0.08819      0.03883      0.97804  7.87s\n",
      "     36       \u001b[36m0.00321\u001b[0m       0.08844      0.03631      0.97814  7.87s\n",
      "     37       \u001b[36m0.00302\u001b[0m       0.08877      0.03401      0.97833  7.87s\n",
      "     38       \u001b[36m0.00285\u001b[0m       0.08908      0.03194      0.97843  7.88s\n",
      "     39       \u001b[36m0.00269\u001b[0m       0.08939      0.03008      0.97843  7.88s\n",
      "     40       \u001b[36m0.00254\u001b[0m       0.08970      0.02837      0.97843  7.88s\n",
      "     41       \u001b[36m0.00242\u001b[0m       0.09001      0.02684      0.97843  7.88s\n",
      "     42       \u001b[36m0.00230\u001b[0m       0.09031      0.02542      0.97853  7.64s\n",
      "     43       \u001b[36m0.00219\u001b[0m       0.09061      0.02413      0.97853  7.80s\n",
      "     44       \u001b[36m0.00209\u001b[0m       0.09092      0.02294      0.97853  7.58s\n",
      "     45       \u001b[36m0.00199\u001b[0m       0.09118      0.02187      0.97863  7.51s\n",
      "     46       \u001b[36m0.00191\u001b[0m       0.09145      0.02087      0.97873  7.51s\n",
      "     47       \u001b[36m0.00183\u001b[0m       0.09172      0.01994      0.97873  7.53s\n",
      "     48       \u001b[36m0.00176\u001b[0m       0.09198      0.01909      0.97893  7.52s\n",
      "     49       \u001b[36m0.00169\u001b[0m       0.09222      0.01830      0.97883  7.51s\n",
      "     50       \u001b[36m0.00162\u001b[0m       0.09247      0.01756      0.97893  7.51s\n",
      "     51       \u001b[36m0.00156\u001b[0m       0.09267      0.01688      0.97893  7.51s\n",
      "     52       \u001b[36m0.00151\u001b[0m       0.09291      0.01624      0.97893  7.51s\n",
      "     53       \u001b[36m0.00146\u001b[0m       0.09312      0.01564      0.97893  7.51s\n",
      "     54       \u001b[36m0.00141\u001b[0m       0.09333      0.01508      0.97893  7.51s\n",
      "     55       \u001b[36m0.00136\u001b[0m       0.09355      0.01455      0.97883  7.51s\n",
      "     56       \u001b[36m0.00132\u001b[0m       0.09374      0.01406      0.97883  7.52s\n",
      "     57       \u001b[36m0.00128\u001b[0m       0.09396      0.01359      0.97893  7.88s\n",
      "     58       \u001b[36m0.00124\u001b[0m       0.09414      0.01315      0.97893  7.03s\n",
      "     59       \u001b[36m0.00120\u001b[0m       0.09434      0.01273      0.97893  4.91s\n",
      "     60       \u001b[36m0.00117\u001b[0m       0.09453      0.01234      0.97893  5.12s\n",
      "Feature vector (100-110): [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Label: 7\n",
      "Predicted: [7]\n"
     ]
    }
   ],
   "source": [
    "print(theano.config.compute_test_value)\n",
    "\n",
    "\n",
    "main(max_epochs=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
